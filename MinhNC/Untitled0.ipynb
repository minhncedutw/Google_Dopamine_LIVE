{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","version":"0.3.2","provenance":[]}},"cells":[{"metadata":{"id":"kkjk7jPbNFNX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1008},"outputId":"e552a18d-3ae4-4f75-e35d-1e1374d7104d","executionInfo":{"status":"ok","timestamp":1537350193488,"user_tz":-480,"elapsed":100086,"user":{"displayName":"MINH NGUYEN CONG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"110000836151781297885"}}},"cell_type":"code","source":["# @title Install necessary packages.\n","#dopamine for RL\n","!pip install --upgrade --no-cache-dir dopamine-rl\n","# dopamine dependencies\n","!pip install cmake\n","#Arcade Learning Environment\n","!pip install atari_py"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting dopamine-rl\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/f1/b1803d7f63dbc087eb78c277ce46b413c66d74db8429b9c77b928e8a4b34/dopamine_rl-1.0.2.tar.gz (44kB)\n","\u001b[K    100% |████████████████████████████████| 51kB 4.0MB/s \n","\u001b[?25hCollecting gin-config>=0.1.1 (from dopamine-rl)\n","  Downloading https://files.pythonhosted.org/packages/a6/1c/d039df49af3da59c7a9b834dbcb82d20f85ea9ad1bc3afa9f23cf360bae2/gin-config-0.1.1.2.tar.gz\n","Requirement already satisfied, skipping upgrade: absl-py>=0.2.2 in /usr/local/lib/python2.7/dist-packages (from dopamine-rl) (0.4.1)\n","Requirement already satisfied, skipping upgrade: tensorflow in /usr/local/lib/python2.7/dist-packages (from dopamine-rl) (1.10.1)\n","Requirement already satisfied, skipping upgrade: opencv-python>=3.4.1.15 in /usr/local/lib/python2.7/dist-packages (from dopamine-rl) (3.4.3.18)\n","Collecting gym>=0.10.5 (from dopamine-rl)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/50/ed4a03d2be47ffd043be2ee514f329ce45d98a30fe2d1b9c61dea5a9d861/gym-0.10.5.tar.gz (1.5MB)\n","\u001b[K    100% |████████████████████████████████| 1.5MB 18.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from gin-config>=0.1.1->dopamine-rl) (1.11.0)\n","Requirement already satisfied, skipping upgrade: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from gin-config>=0.1.1->dopamine-rl) (1.1.6)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (1.15.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (3.6.1)\n","Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (2.0.0)\n","Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (0.2.0)\n","Requirement already satisfied, skipping upgrade: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (1.14.5)\n","Requirement already satisfied, skipping upgrade: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (0.31.1)\n","Requirement already satisfied, skipping upgrade: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (1.10.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (1.1.0)\n","Requirement already satisfied, skipping upgrade: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (1.0.post1)\n","Requirement already satisfied, skipping upgrade: setuptools<=39.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (39.1.0)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->dopamine-rl) (0.7.1)\n","Requirement already satisfied, skipping upgrade: requests>=2.0 in /usr/local/lib/python2.7/dist-packages (from gym>=0.10.5->dopamine-rl) (2.18.4)\n","Collecting pyglet>=1.2.0 (from gym>=0.10.5->dopamine-rl)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n","\u001b[K    100% |████████████████████████████████| 1.0MB 24.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow->dopamine-rl) (3.2.0)\n","Requirement already satisfied, skipping upgrade: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow->dopamine-rl) (1.0.2)\n","Requirement already satisfied, skipping upgrade: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow->dopamine-rl) (4.2.0)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow->dopamine-rl) (0.14.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow->dopamine-rl) (2.6.11)\n","Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.0->gym>=0.10.5->dopamine-rl) (2.6)\n","Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.0->gym>=0.10.5->dopamine-rl) (1.22)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.0->gym>=0.10.5->dopamine-rl) (2018.8.24)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.0->gym>=0.10.5->dopamine-rl) (3.0.4)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python2.7/dist-packages (from pyglet>=1.2.0->gym>=0.10.5->dopamine-rl) (0.16.0)\n","Installing collected packages: gin-config, pyglet, gym, dopamine-rl\n","  Running setup.py install for gin-config ... \u001b[?25l-\b \b\\\b \bdone\n","\u001b[?25h  Running setup.py install for gym ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n","\u001b[?25h  Running setup.py install for dopamine-rl ... \u001b[?25l-\b \bdone\n","\u001b[?25hSuccessfully installed dopamine-rl-1.0.2 gin-config-0.1.1.2 gym-0.10.5 pyglet-1.3.2\n","Collecting cmake\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/b2/a25e3bac772625375f8d4e51ae696b1b7ce0c39e5e30d201b18f6ce31f46/cmake-3.12.0-cp27-cp27mu-manylinux1_x86_64.whl (17.7MB)\n","\u001b[K    100% |████████████████████████████████| 17.7MB 1.2MB/s \n","\u001b[?25hInstalling collected packages: cmake\n","Successfully installed cmake-3.12.0\n","Collecting atari_py\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/38/3c6716ac9031a686cc3228f3855e48c08a40e4d7c490dd4c21c65b465205/atari-py-0.1.1.tar.gz (760kB)\n","\u001b[K    100% |████████████████████████████████| 768kB 9.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from atari_py) (1.14.5)\n","Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from atari_py) (1.11.0)\n","Building wheels for collected packages: atari-py\n","  Running setup.py bdist_wheel for atari-py ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ac/79/85/b21b404d3469c3028aea3b7a1dfe9d9bf9827a20cee6a118bd\n","Successfully built atari-py\n","Installing collected packages: atari-py\n","Successfully installed atari-py-0.1.1\n"],"name":"stdout"}]},{"metadata":{"id":"ACdrfu2aNKHk","colab_type":"code","colab":{}},"cell_type":"code","source":["# @title Necessary imports and globals.\n","#matrix math\n","import numpy as np\n","#load files\n","import os\n","#DQN for baselines\n","from dopamine.agents.dqn import dqn_agent\n","#high level agent-environment excecution engine\n","from dopamine.atari import run_experiment\n","#visualization + data downloading\n","from dopamine.colab import utils as colab_utils\n","#warnings\n","from absl import flags\n","\n","#where to store training logs\n","BASE_PATH = '/tmp/colab_dope_run'  # @param\n","#which arcade environment?\n","GAME = 'Asterix'  # @param\n","#define where to store log data\n","LOG_PATH = os.path.join(BASE_PATH, 'basic_agent', GAME)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zdmNOt-rNRlk","colab_type":"code","colab":{}},"cell_type":"code","source":["class BasicAgent(object):\n","  \"\"\"This agent randomly selects an action and sticks to it. It will change\n","  actions with probability switch_prob.\"\"\"\n","  def __init__(self, sess, num_actions, switch_prob=0.1):\n","    #tensorflow session\n","    self._sess = sess\n","    #how many possible actions can it take?\n","    self._num_actions = num_actions\n","    # probability of switching actions in the next timestep?\n","    self._switch_prob = switch_prob\n","    #initialize the action to take (randomly)\n","    self._last_action = np.random.randint(num_actions)\n","    #not debugging\n","    self.eval_mode = False\n","  \n","  #How select an action? \n","  #we define our policy here\n","  def _choose_action(self):\n","    if np.random.random() <= self._switch_prob:\n","      self._last_action = np.random.randint(self._num_actions)\n","    return self._last_action\n","    \n","  #when it checkpoints during training, anything we should do?\n","  def bundle_and_checkpoint(self, unused_checkpoint_dir, unused_iteration):\n","    pass\n","    \n","  #loading from checkpoint\n","  def unbundle(self, unused_checkpoint_dir, unused_checkpoint_version,\n","               unused_data):\n","    pass\n","  \n","  #first action to take\n","  def begin_episode(self, unused_observation):\n","    return self._choose_action()\n","  \n","  #cleanup\n","  def end_episode(self, unused_reward):\n","    pass\n","  \n","  #we can update our policy here\n","  #using the reward and observation\n","  #dynamic programming, Q learning, monte carlo methods, etc.\n","  def step(self, reward, observation):\n","    return self._choose_action()\n","  \n","def create_basic_agent(sess, environment):\n","  \"\"\"The Runner class will expect a function of this type to create an agent.\"\"\"\n","  return BasicAgent(sess, num_actions=environment.action_space.n,\n","                     switch_prob=0.2)\n","\n","# Create the runner class with this agent. We use very small numbers of steps\n","# to terminate quickly, as this is mostly meant for demonstrating how one can\n","# use the framework. We also explicitly terminate after 110 iterations (instead\n","# of the standard 200) to demonstrate the plotting of partial runs.\n","basic_runner = run_experiment.Runner(LOG_PATH,\n","                                      create_basic_agent,\n","                                      game_name=GAME,\n","                                      num_iterations=200,\n","                                      training_steps=10,\n","                                      evaluation_steps=10,\n","                                      max_steps_per_episode=100)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JG08f0w6NTbG","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}